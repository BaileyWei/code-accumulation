{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertJapaneseTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at /data/wjb/pretrained_weight/bert-base-japanese and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/data/wjb/pretrained_weight/bert-base-japanese')\n",
    "model = BertForPreTraining.from_pretrained('/data/wjb/pretrained_weight/bert-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/scarlett/Japan/train','r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for paragraph in text:\n",
    "    sentences = [\n",
    "        sentence for sentence in paragraph.split('。') if sentence != ''\n",
    "    ]\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        for i in range(10):\n",
    "            start = random.randint(0, num_sentences-2)\n",
    "            # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "            if random.random() >= 0.5:\n",
    "                # this is IsNextSentence\n",
    "                sentence_a.append(sentences[start])\n",
    "                sentence_b.append(sentences[start+1])\n",
    "                label.append(0)\n",
    "            else:\n",
    "                index_neg_text = random.randint(0, len(text)-1)\n",
    "                neg_text = text[index_neg_text]\n",
    "                neg_sentences = neg_text.split('。')\n",
    "                index_neg_sentence = random.randint(0, len(neg_sentences)-1)\n",
    "                # this is NotNextSentence\n",
    "                sentence_a.append(sentences[start])\n",
    "                sentence_b.append(neg_sentences[index_neg_sentence])\n",
    "                label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99270"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt',\n",
    "                   max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor mask=1, \n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 2) * \\\n",
    "           (inputs.input_ids != 3) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MASK]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidog/.conda/envs/jin/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "loader_test = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c696d2b4fe4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# and move our model over to the selected device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aidog/.conda/envs/jin/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "eval_loss: tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "train_loss: tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train_loss: tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    #loop = tqdm(loader, leave=True)\n",
    "    #for batch in loop:\n",
    "    for i,batch in enumerate(loader_train):\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        print('train_loss:', loss)\n",
    "        if i%3==0:\n",
    "            loss_all_eval = 0\n",
    "            for i_eval,batch_eval in enumerate(loader_test):\n",
    "                input_ids_eval = batch_eval['input_ids'].to(device)\n",
    "                token_type_ids_eval = batch_eval['token_type_ids'].to(device)\n",
    "                attention_mask_eval = batch_eval['attention_mask'].to(device)\n",
    "                next_sentence_label_eval = batch_eval['next_sentence_label'].to(device)\n",
    "                labels_eval = batch_eval['labels'].to(device)\n",
    "                outputs_eval = model(input_ids_eval, \n",
    "                                     attention_mask = attention_mask_eval,\n",
    "                                     token_type_ids = token_type_ids_eval,\n",
    "                                     next_sentence_label = next_sentence_label_eval,\n",
    "                                     labels = labels_eval)\n",
    "                loss_eval = outputs_eval.loss\n",
    "                loss_all_eval += loss_eval\n",
    "            print('eval_loss:', loss_all_eval/(i_eval+1))\n",
    "                \n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        #loop.set_description(f'Epoch {epoch}')\n",
    "        #loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch=7\n",
    "str(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jin(python3)",
   "language": "python",
   "name": "jin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
